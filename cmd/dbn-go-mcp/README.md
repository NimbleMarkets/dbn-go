# `dbn-go-mcp` DBN MCP Server

`dbn-go-mcp` is a [Model Context Protocol (MCP)](https://www.anthropic.com/news/model-context-protocol) for Databento services.   It requires your [Databento API Key](https://databento.com/portal/keys); since this program is executed by a host program (like Claude Desktop), the preferred way to is to store the API key in a file and use `--keyfile` or the `DATABENTO_API_KEY_FILE` environment variable.  It supports both `STDIO` and `SSE` MCP transports.

*CAUTION: This program incurs billing!*

Typically, you do not run this directly, but your LLM host program will.  But here are the command-line arguments:

```
$ dbn-go-mcp --help
usage: dbn-go-mcp -k <api_key> [opts]

  -h, --help              Show help
  -k, --key string        Databento API key (or set 'DATABENTO_API_KEY' envvar)
  -f, --key-file string   File to read Databento API key from (or set 'DATABENTO_API_KEY_FILE' envvar)
  -l, --log-file string   Log file destination (or MCP_LOG_FILE envvar) (default "dbn-go-mcp.log")
  -j, --log-json          Log in JSON (default is plaintext)
  -c, --max-cost float    Max cost, in dollars, for a query (<=0 is unlimited) (default 1)
      --port string       host:port to listen to SSE connections
      --sse               Use SSE Transport (default is STDIO transport)
  -v, --verbose           Verbose logging
  ```

Currenty, the following tools are supported by the `dbn` MCP server:

| Tool | Params | Description |
|------|--------|-------------|
| `get_cost` | `dataset`, `schema`, `start`, `end`, `symbol` | Returns the estimated cost of all records of a DBN schema for a given date range. |
| `get_range` |`dataset`, `schema`, `start`, `end`, `symbol` | Returns all records of a DBN dataset/schema for a given date range. |

You can run a CLI test using the `STDIO` mode to list available tools:

```bash
echo '{"method":"tools/list","params":{},"jsonrpc":"2.0","id":1}' | dbn-go-mcp | jq
```

<details>
<summary>Results are the dbn-go-mcp schema in JSON. Click to expand.</summary>

```
time=2025-04-01T14:13:28.436-04:00 level=INFO msg="MCP STDIO server started"
{
  "jsonrpc": "2.0",
  "id": 2,
  "result": {
    "tools": [
      {
        "description": "Returns the estimated cost of all records of a DBN schema for a given symbol and date range",
        "inputSchema": {
          "type": "object",
          "properties": {
            "dataset": {
              "description": "Dataset to query",
              "enum": [
                "ARCX.PILLAR",
                "DBEQ.BASIC",
                "EPRL.DOM",
                "EQUS.MINI",
                "EQUS.SUMMARY",
                "GLBX.MDP3",
                "IEXG.TOPS",
                "IFEU.IMPACT",
                "MEMX.MEMOIR",
                "NDEX.IMPACT",
                "OPRA.PILLAR",
                "XASE.PILLAR",
                "XBOS.ITCH",
                "XCHI.PILLAR",
                "XCIS.TRADESBBO",
                "XNAS.BASIC",
                "XNAS.ITCH",
                "XNYS.PILLAR",
                "XPSX.ITCH"
              ],
              "type": "string"
            },
            "end": {
              "description": "end of range, as ISO 8601 datetime",
              "type": "string"
            },
            "schema": {
              "description": "Schema to query",
              "enum": [
                "mbo",
                "mbp-1",
                "mbp-10",
                "bbo-1s",
                "bbo-1m",
                "tbbo",
                "trades",
                "ohlcv-1s",
                "ohlcv-1m",
                "ohlcv-1h",
                "ohlcv-1d",
                "definition",
                "statistics",
                "status",
                "imbalance"
              ],
              "type": "string"
            },
            "start": {
              "description": "start of range, as ISO 8601 datetime",
              "type": "string"
            },
            "symbol": {
              "description": "Symbol to query",
              "type": "string"
            }
          },
          "required": [
            "dataset",
            "schema",
            "symbol",
            "start",
            "end"
          ]
        },
        "name": "get_cost"
      },
      {
        "description": "Returns all records of a DBN dataset/schema for a given symbol and date range",
        "inputSchema": {
          "type": "object",
          "properties": {
            "dataset": {
              "description": "Dataset to query",
              "enum": [
                "ARCX.PILLAR",
                "DBEQ.BASIC",
                "EPRL.DOM",
                "EQUS.MINI",
                "EQUS.SUMMARY",
                "GLBX.MDP3",
                "IEXG.TOPS",
                "IFEU.IMPACT",
                "MEMX.MEMOIR",
                "NDEX.IMPACT",
                "OPRA.PILLAR",
                "XASE.PILLAR",
                "XBOS.ITCH",
                "XCHI.PILLAR",
                "XCIS.TRADESBBO",
                "XNAS.BASIC",
                "XNAS.ITCH",
                "XNYS.PILLAR",
                "XPSX.ITCH"
              ],
              "type": "string"
            },
            "end": {
              "description": "end of range, as ISO 8601 datetime",
              "type": "string"
            },
            "schema": {
              "description": "Schema to query",
              "enum": [
                "mbo",
                "mbp-1",
                "mbp-10",
                "bbo-1s",
                "bbo-1m",
                "tbbo",
                "trades",
                "ohlcv-1s",
                "ohlcv-1m",
                "ohlcv-1h",
                "ohlcv-1d",
                "definition",
                "statistics",
                "status",
                "imbalance"
              ],
              "type": "string"
            },
            "start": {
              "description": "start of range, as ISO 8601 datetime",
              "type": "string"
            },
            "symbol": {
              "description": "Symbol to query",
              "type": "string"
            }
          },
          "required": [
            "dataset",
            "schema",
            "symbol",
            "start",
            "end"
          ]
        },
        "name": "get_range"
      }
    ]
  }
}
```
</details>

## MCP Host Tool Configuration

To use this the MCP server, you must configure your host program to use it.  We will illustrate with Claude Desktop and Ollama with `mcphost` as they have the same configuration format.   We must find the `dbn-go-mcp` program on our system; the example below shows where `dbn-go` is installed with MacOS Homebrew (perhaps build your own and point at that!).  We also store our Databento API key in a plain text file.  The [configuration JSON](./claude_desktop_config.json) points the host to that and also sets a per-call budget of $1.50.

```json
{
  "mcpServers": {
    "dbn": {
      "command": "/opt/homebrew/bin/dbn-go-mcp",
      "args": [
        "--key-file", "/etc/dbn_api.txt",
        "--max-cost", "1.50"
      ]
    }
  }
}
```

*Please be careful!*  This is experimental software and it is an LLM using your Databento API key. It may incur costs!  You can use the `--max-cost` parameter to limit the cost of each call.  You can also assign billing limits in your Databento account.  [**THERE IS NO WARRANTY.**](../LICENSE.txt)

## Claude Desktop

Using Claude Desktop, you can follow [their configuration tutorial](https://modelcontextprotocol.io/quickstart/user) but substitute the configuration above.  With that in place, you can ask Claude question and it will use the server.  Here's example conversations:

<p align="center"><a href="./claude_get_cost.png"><img src="./claude_get_cost.png" alt="Claude uses dbn-go-mcp to answer 'How much would it cost for Databento tbbo data for TSLA 2024 on XNAS.ITCH?'" width="45%" valign="middle"></a>&nbsp;<a href="./claude_qqq.png"><img src="./claude_qqq.png" alt="Claude uses dbn-go-mcp to answer 'using dbn, what was the highest trade price of QQQ on ITCH on the day after thanksgiving 2023?'" width="45%" valign="middle"></a></p>

It's interesting that the verbose JSON `trades` output is too much for Claude, so it adjusts its strategy to get `ohlcv` data.  It also shows that this tool needs to be improved to allow Claude to work with it -- we'll figure it out over time!  I asked Claude what it would like and it suggested more filtering (of fields and records) as well as use-specific endpoints.  Please [open an issue](https://github.com/NimbleMarkets/dbn-go/issues) with any ideas.

## Ollama with `mcphost`

For local inferencing, there are MCP hosts that support [Ollama](https://ollama.com/download).  You can use any [Ollama LLM that supports "Tools"](https://ollama.com/search?c=tools).  We experimented with [`mcphost`](https://github.com/mark3labs/mcphost), authored by the developer of the [`mcp-go` library](https://github.com/mark3labs/mcp-go) that peformed the heavy lifting for us.

Here's how to install and run with it with the configuration above, stored in `mcp.json`:

```
$ go install github.com/mark3labs/mcphost@latest
$ mcphost -m ollama:llama3.3 --config mcp.json
...chat away...
```

### Local Inferencing Experiments

Let's try it this out with [`llama3.3:70b`](https://ollama.com/library/llama3.3):

<details>
<summary>Conversation with llama3.3. Click to expand.</summary>

```
$ go install github.com/mark3labs/mcphost@latest
$ mcphost -m ollama:llama3.3 --config mcp.json
2025/04/01 10:43:03 INFO Model loaded provider=ollama model=llama3.3
2025/04/01 10:43:03 INFO Initializing server... name=dbn
2025/04/01 10:43:03 INFO Server connected name=dbn
2025/04/01 10:43:03 INFO Tools loaded server=dbn count=2

  You: How much would it cost for Databento tbbo data for TSLA 2024 on ITCH?

  Assistant:
2025/04/01 10:44:10 INFO ðŸ”§ Using tool name=dbn__get_cost

  Assistant:
  The cost for Databento tbbo data for TSLA in 2024 on ITCH would be $25.16. The total data size is approximately 4.5 GB, and
  the query contains 56,291,497 records.

  You: what was the highest trade price of QQQ on ITCH on the day after thanksgiving 2023?

  Assistant:

2025/04/01 10:45:44 INFO ðŸ”§ Using tool name=dbn__get_range

  Assistant:

  The provided text appears to be a series of financial transactions or trade records, likely from an exchange or trading
  platform. Each line represents a single transaction and includes various details about the trade. Here's a breakdown of the
  information contained in each line:

  1. ts_recv: This is the timestamp when the transaction was received. It's in a format that includes year, month, day, hour,
  minute, second, and fractional seconds (e.g., 2023-11-24T21:32:16.865572599Z).
  2. hd: This stands for "header" and contains another set of timestamps (ts_event) related to when the event occurred, along
  with other details like rtype (record type), publisher_id, and instrument_id.
  3. action: Indicates the type of action performed in the transaction, which is always "T" (trade) in the provided examples.
  4. side: Specifies whether the trade was a buy ("B") or sell ("A"), with "N" not being observed in the given data but could
  potentially represent other types of trades or actions in different contexts.
  5. depth: The depth of the trade, which is always 0 in these examples. In financial markets, depth can refer to the number
  of price levels (bid and ask) available for a security.
  6. price: The price at which the transaction occurred.
  7. size: The quantity or size of the transaction.
  8. flags: Additional flags that may provide more context about the trade, such as whether it was part of an iceberg order
  (a large order that is broken up into smaller pieces to avoid detection) or other special conditions. 130 seems to be a
  common flag in these examples, but without specific documentation, its meaning can only be speculated.
  9. ts_in_delta: This might represent the delta (difference) in time between two significant events related to the trade,
  though its exact interpretation depends on the context of the trading system or platform.
  10. sequence: A sequence number assigned to each transaction, likely for ordering and tracking purposes within the system.
  11. symbol: The financial instrument or security being traded, which is consistently "QQQ" in these examples, referring to
  the Invesco QQQ ETF, an exchange-traded fund that tracks the Nasdaq-100 Index.

  These transactions seem to be related to trading activities on a specific financial platform or exchange, with each entry
  detailing a trade event involving the QQQ ETF. The exact nature of some fields (like flags and ts_in_delta) would require
  more context or documentation from the system generating these records to fully understand their significance.
```

</details>
<p></p>

Hmmmm.... `llama3.3` did great with the `get_cost`, but it didn't perform well with `get_range`.  Claude reasoned a way around the limitations, but `llama3.3` is not a reasoning model.

Let's try a Tool-supporting Ollama reasoning model, like [`qwq`](https://ollama.com/library/qwq):

<details>
<summary>Conversation with qwq. Click to expand.</summary>

```
mcphost -m ollama:qwq:32b --config mcp.json
2025/04/01 11:38:02 INFO Model loaded provider=ollama model=qwq:32b
2025/04/01 11:38:02 INFO Initializing server... name=dbn
2025/04/01 11:38:02 INFO Server connected name=dbn
2025/04/01 11:38:02 INFO Tools loaded server=dbn count=2

  You: How much would it cost for Databento tbbo data for TSLA 2024 on ITCH?

  Assistant:

2025/04/01 11:38:39 INFO ðŸ”§ Using tool name=dbn__get_cost

  Assistant:



  First, I need to present this information clearly. The user probably wants to know the total cost, so I'll mention the $25.06 upfront. Then, maybe they're
  interested in how that's calculated. The data size is 4,483,796,480 bytes, which is roughly 4.48 gigabytes. The record count is over 56 million, which shows the
  volume of data.

  I should also note the dataset used (XNAS.ITCH) and the symbol (TSLA) to confirm everything's correct. Maybe mention the date range again to be thorough. The user
  might not be familiar with the units, so converting bytes to gigabytes helps. I should keep it concise but informative, making sure all the key numbers are
  highlighted. Let me structure this so the answer is easy to follow, starting with the total cost and then breaking down the data size and records. Double-checking
  the parameters in the tool response to ensure accuracy. Alright, that should cover their query.

  The estimated cost for Databento TBBO (ticker-by-ticker optimal) data for TSLA in 2024 (January 1 to December 31, 2024) from the XNAS.ITCH dataset (NASDAQ ITCH
  feed)
  is:

  $25.06

  ### Details:

  â€¢ Data size: ~4.48 gigabytes (4,483,796,480 bytes)
  â€¢ Record count: 56,047,456 events
  â€¢ Dataset: XNAS.ITCH (NASDAQ ITCH data)
  â€¢ Schema: tbbo (optimal bid/offer tracking)

  This cost is based on Databento's pricing structure for raw data retrieval. Let me know if you need further clarification!



  You: using dbn,  what was the highest trade price of QQQ on ITCH on the day after thanksgiving 2023?

  Assistant:



  Next, the user is asking for the highest trade price, which means I need to access trade data. The dataset mentioned is ITCH, so looking at the available datasets,
  XNAS.ITCH is the correct one for NASDAQ ITCH data. The schema for trade data in Databento is usually "trades," so I should use that.

  The function to retrieve the data is dbn__get_range, which fetches all records within a date range. The parameters required are dataset, schema, symbol, start, and
  end. Since the user wants the highest price on a specific day, the start and end should be set to November 24, 2023, but to be precise, maybe include the entire
  day by setting start as the beginning of the day and end as the next day.

  Wait, the end parameter is exclusive, so maybe end should be the next day's start. But I need to confirm the exact format. The parameters need to be in ISO 8601
  datetime. So start: "2023-11-24T00:00:00Z" and end: "2023-11-25T00:00:00Z" would cover the entire 24th.

  However, the user might not know that the highest trade price could be found by querying the trades data and then processing it. Since the function dbn__get_range
  returns the raw data, the user might expect me to process it further, but since I can only call the function, I need to make sure the parameters are correct. So
  the function call would be to get the trades schema for QQQ on that date. The user can then analyze the data to find the highest price, but since they asked for
  the highest price, maybe I need to mention that they need to process the data further, but the function to get the data is as called.

  Wait, but the tools provided don't have a function that directly calculates the highest price. The available functions are get_cost and get_range. So I can only
  help them retrieve the data, not compute the max. Therefore, I should call dbn__get_range with the correct parameters to get the trade data for that day, and then
  inform the user that they need to process it to find the highest price. Alternatively, if there's another approach, but given the tools, that's the way.

  Double-checking the parameters: symbol QQQ, dataset XNAS.ITCH, schema trades, start and end dates as specified. That should be it.

  To find the highest trade price of QQQ on NASDAQ ITCH (XNAS.ITCH) on the day after Thanksgiving 2023, we first need to determine the exact date.

  â€¢ Thanksgiving 2023: November 23, 2023
  â€¢ Day after Thanksgiving: November 24, 2023

  We will use the trades schema (contains trade prices) from the XNAS.ITCH dataset. Here's the required query:

    dbn__get_range(
        dataset="XNAS.ITCH",
        schema="trades",
        symbol="QQQ",
        start="2023-11-24T00:00:00Z",
        end="2023-11-25T00:00:00Z"
    )

  ### Steps to find the highest price:

  1. Run the above query to retrieve all trades for QQQ on November 24, 2023.
  2. Extract the price field from the trade records.
  3. Compute the maximum value of price.

  If you need further assistance processing the data, let me know!



  You: can you run that for me?

  Assistant:



  First, I need to recall the tools available. The functions I can use are dbn__get_cost and dbn__get_range. The user previously wanted the highest trade price of
  QQQ on the day after Thanksgiving 2023, so I suggested using dbn__get_range to get the trades data. Now they're asking me to actually run that for them.

  Wait a second, the tools here are just for generating the function calls, not actually executing them. I can't run the query myself; I can only help them form the
  correct function call. The user might not realize that I can't execute code or access live data. I should clarify that I can't run the query but can provide the
  exact parameters they need to use in their own environment.

  Looking back at the tools provided, the dbn__get_range function is meant to retrieve the data, but processing it (like finding the max price) isn't something I can
  do here. The user might need to use that data in their own code or tools. I should explain that they need to execute the function call themselves and then process
  the results to find the highest price.

  Also, I should double-check the parameters to make sure they're correct. The dataset is XNAS.ITCH, symbol QQQ, schema trades, and the date range from November 24th
  00:00 to November 25th 00:00 in ISO format. That seems right.

  I should also mention that they might need to handle the data once they get it, like looking at the 'price' field and finding the maximum value. If they're using
  Python, maybe suggest using pandas or another library to process the data. But since they might not have that context, I should keep it general.

  I should also consider if there's any cost involved. The dbn__get_cost function could check the cost of the query, but the user didn't mention that. Maybe they
  just want the data, but it's worth noting that they should check if there are any costs associated with running that query.

  Putting it all together, I need to inform them that I can't execute the query but can provide the exact function call. Then explain the next steps they should take
  to get and process the data. Make sure to be clear and helpful without overstepping my capabilities.

  I cannot directly execute code or access live data, but I can provide you with the exact function call you need to run in your environment to retrieve the data for
  QQQ trades on November 24, 2023. Here it is again:

    dbn__get_range(
        dataset="XNAS.ITCH",
        schema="trades",
        symbol="QQQ",
        start="2023-11-24T00:00:00Z",
        end="2023-11-25T00:00:00Z"
    )

  ### Steps to use this:

  1. Copy the code above into your Python script or notebook.
  2. Execute it in an environment where the dbn__get_range function is connected to a data source (e.g., a financial data API or database like TickData, Polygon, or
  your brokerageâ€™s API).
  3. Process the output: The function will return raw trade data (e.g., timestamps, prices, volumes). Youâ€™ll need to extract the price field and compute its maximum
  value to find the highest trade price for the day.

  --------

  ### If you donâ€™t have access to this data:

  â€¢ You might need to use a financial data provider (e.g., Polygon.io https://polygon.io/, Tiingo https://tiingo.com/, or Alpha Vantage https://www.alphavantage.co/)
  to fetch historical trade data.
  â€¢ For free options, tools like Yahoo Finance https://finance.yahoo.com/ or Alpha Vantage https://www.alphavantage.co/ can provide OHLC (Open/High/Low/Close) data,
  but they may not include intraday trade-level details.

  Let me know if youâ€™d like help with code to process the data once you retrieve it!



  You: use the dbn mcp server tool to run that

  Assistant:



  First, I need to check the tools available. The functions provided are dbn__get_cost and dbn__get_range. The user mentioned "DBN MCP server tool," which might be a
  specific interface or client for these functions. Since the tools are predefined, I can only use those two functions.

  Wait, the user might be referring to the actual API endpoint or command-line tool they have access to. Since I can't execute code, I can only structure the
  function
  call correctly. They probably need the exact parameters formatted for their DBN MCP tool.

  Looking at their request again, they want to "run that" which refers to the previous query. The parameters are still the same: dataset XNAS.ITCH, schema trades,
  symbol QQQ, start and end dates. The function dbn__get_range is the right one here.

  I should make sure the parameters are correctly formatted in ISO 8601. The start is 2023-11-24T00:00:00Z and end is 2023-11-25T00:00:00Z. That covers the entire
  day of
  the 24th.

  I should present the function call again, emphasizing that it's intended for their DBN MCP environment. Maybe they need to input this into a specific tool or API
  request. Also, I should mention that they might need authentication or additional parameters not specified here, but since the tools are predefined, I can only
  provide the core parameters.

  I should also note that if they're using a CLI or another interface, the syntax might differ slightly, but the essential arguments remain the same. They might need
  to adjust based on their tool's requirements.

  Double-checking everything: dataset is correct for NASDAQ ITCH data, schema is trades, symbol is QQQ. Dates are correct for the specified day. No mistakes there.
  Alright, time to format the response clearly.

  To use the DBN MCP server tool to retrieve the QQQ trade data for November 24, 2023, you need to format the request correctly. Here is the exact command or API
  call you should use in your DBN MCP environment:

    dbn__get_range(
        dataset="XNAS.ITCH",
        schema="trades",
        symbol="QQQ",
        start="2023-11-24T00:00:00Z",
        end="2023-11-25T00:00:00Z"
    )

  ### Explanation:

  â€¢ dataset="XNAS.ITCH": Specifies the NASDAQ ITCH feed (tick-level data).
  â€¢ schema="trades": Requests trade data (price, size, timestamps).
  â€¢ symbol="QQQ": The ticker symbol you want.
  â€¢ start/end: The time range for November 24, 2023 (inclusive of the full day).

  --------

  ### Steps to Run This:

  1. Authentication: Ensure youâ€™re authenticated with the DBN MCP server (e.g., via API keys or a token).
  2. Environment: Use the DBN Python client library or CLI tool to execute this function.
  3. Execution: Run the code above. The response will be raw trade data for QQQ on that day.
  4. Processing: Extract the price field and find the maximum value to get the highest trade price.

  --------

  ### If You Need Cost Estimates First:

  Before running the query, use dbn__get_cost to check the cost:

    dbn__get_cost(
        dataset="XNAS.ITCH",
        schema="trades",
        symbol="QQQ",
        start="2023-11-24T00:00:00Z",
        end="2023-11-25T00:00:00Z"
    )

  Let me know if you need help interpreting the results!



  You: go ahead and use the tool, you have my permission and api key

  Assistant:



  First, I remember that as an AI, I can't actually execute code or access external APIs directly. My role is to provide the necessary information and commands, but
  I can't perform actions that require API access. The user might not realize that I can't interact with external systems.

  Looking back at the previous messages, they wanted the highest trade price of QQQ on a specific date. I already provided the function call they need to run in
  their own environment. Now they're insisting I use the tool with their API key. But I can't do that. I should explain that again clearly.

  I should also make sure they understand the steps they need to take themselves. Maybe they need to copy the code into their own setup with the API key configured.
  I'll reiterate the exact parameters and maybe suggest how they can implement it securely, like using environment variables for the API key.

  Also, I should avoid any mention of handling the API key myself to prevent any misunderstanding. Safety is important here. Let me structure the response to guide
  them properly without overstepping my capabilities.

  I cannot directly execute code or access external APIs, including DBN's MCP server, even with an API key. However, I can provide you with the exact code snippet to
  run in your own environment (e.g., Python script, notebook, or CLI tool) using your API key. Here's how to proceed:

  --------

  ### Step 1: Install the DBN Python Client (if not already installed)

    pip install dbn-api-client  # Example package name (check DBN's official docs)

  --------

  ### Step 2: Run the Query with Your API Key

    from dbn_api import DBNClient  # Adjust import based on DBN's library

    # Initialize client with your API key
    client = DBNClient(api_key="YOUR_API_KEY_HERE")

    # Execute the query for QQQ trades on 2023-11-24
    response = client.query(
        dataset="XNAS.ITCH",
        schema="trades",
        symbol="QQQ",
        start="2023-11-24T00:00:00Z",
        end="2023-11-25T00:00:00Z"
    )

    # Extract and process the data
    trades = response.data
    highest_price = max(float(trade["price"]) for trade in trades)
    print(f"Highest QQQ trade price on 2023-11-24: {highest_price}")

  --------

  ### Notes:

  1. API Key Security: Ensure your API key is stored securely (e.g., in environment variables, not hardcoded).
  2. Rate Limits: Check DBN's API documentation for rate limits or cost estimates before running large queries.
  3. Error Handling: Add try/except blocks to handle authentication or query errors.

  Let me know if you need help debugging or interpreting the results!
```
</details>

<p></p>

`qwq` successfully used `get_cost`.  The model understood the `get_range` tool to answer the question, but it refused to actually use it, despite my demands.

## Next Steps

We need to understand how to better structure and present these tools to the LLMs.   It might just be a matter of more [verbose MCP Tool descriptions](../dbn-go-mcp/main.go#L224).

Operationally, perhaps we could add allow/deny lists for datasets and schemas, as well as stronger budgeting and auditing tools.
